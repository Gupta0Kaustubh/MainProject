{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4ddaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ecdf104-8c82-4d78-9832-f857e7510947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=\"kaustubh\",\n",
    "        password=\"@@Kaustubh123\",\n",
    "        account=\"rh57156.central-india.azure\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"Main_Project\",\n",
    "        schema=\"Main_Project_Schema_Mart\",\n",
    "        role = \"ACCOUNTADMIN\"\n",
    "    )\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35193df6-3682-4a8f-96af-e6dfb36018b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "\n",
    "# Execute SQL query to fetch data\n",
    "sql_query = f\"SELECT * FROM TOTALINFO\"\n",
    "cur.execute(sql_query)\n",
    "\n",
    "# Fetch data into a pandas DataFrame\n",
    "data = cur.fetchall()\n",
    "columns = [col[0] for col in cur.description]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Close cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa8851a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERID</th>\n",
       "      <th>FULLNAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>PHONENUMBER</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOJ</th>\n",
       "      <th>SPECIALIZATION</th>\n",
       "      <th>DOB</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAINERSPECIALIZATION</th>\n",
       "      <th>TRAININGNAME</th>\n",
       "      <th>OPTIMIZEDDURATION</th>\n",
       "      <th>DIFFICULTYLEVEL</th>\n",
       "      <th>TRAININGSTATUS</th>\n",
       "      <th>ASSESSMENT_PERCENTAGE_DONE</th>\n",
       "      <th>ASSESSMENT_COMPLETION_TIME_IN_HOURS</th>\n",
       "      <th>SCOREACHIEVEDINQUIZ</th>\n",
       "      <th>QUIZPASSEDORFAILED</th>\n",
       "      <th>RATINGGIVENBYTRAINER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>[Continuous Deployment</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>GraphQL</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>PostgreSQL</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>Node.js]</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emp_172</td>\n",
       "      <td>Jonathan Patel</td>\n",
       "      <td>gonzalesbrian@example.org</td>\n",
       "      <td>001-515-605-2768x915</td>\n",
       "      <td>Male</td>\n",
       "      <td>13-01-2021</td>\n",
       "      <td>[MongoDB</td>\n",
       "      <td>14-07-1939</td>\n",
       "      <td>West Paulland</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science Essentials</td>\n",
       "      <td>23.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>pending</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    USERID        FULLNAME                      EMAIL           PHONENUMBER  \\\n",
       "0  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "1  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "2  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "3  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "4  Emp_172  Jonathan Patel  gonzalesbrian@example.org  001-515-605-2768x915   \n",
       "\n",
       "   GENDER         DOJ          SPECIALIZATION         DOB              CITY  \\\n",
       "0  Female  23-09-2020  [Continuous Deployment  09-09-1996  South Taylorberg   \n",
       "1  Female  23-09-2020                 GraphQL  09-09-1996  South Taylorberg   \n",
       "2  Female  23-09-2020              PostgreSQL  09-09-1996  South Taylorberg   \n",
       "3  Female  23-09-2020                Node.js]  09-09-1996  South Taylorberg   \n",
       "4    Male  13-01-2021                [MongoDB  14-07-1939     West Paulland   \n",
       "\n",
       "            STATE  ...                              TRAINERSPECIALIZATION  \\\n",
       "0  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "1  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "2  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "3  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "4         Vermont  ...                                               None   \n",
       "\n",
       "              TRAININGNAME OPTIMIZEDDURATION DIFFICULTYLEVEL TRAININGSTATUS  \\\n",
       "0  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "1  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "2  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "3  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "4  Data Science Essentials              23.0            easy        pending   \n",
       "\n",
       "  ASSESSMENT_PERCENTAGE_DONE ASSESSMENT_COMPLETION_TIME_IN_HOURS  \\\n",
       "0                       87.0                                 NaN   \n",
       "1                       87.0                                 NaN   \n",
       "2                       87.0                                 NaN   \n",
       "3                       87.0                                 NaN   \n",
       "4                        0.0                                 NaN   \n",
       "\n",
       "   SCOREACHIEVEDINQUIZ QUIZPASSEDORFAILED RATINGGIVENBYTRAINER  \n",
       "0                  NaN                                     4.0  \n",
       "1                  NaN                                     4.0  \n",
       "2                  NaN                                     4.0  \n",
       "3                  NaN                                     4.0  \n",
       "4                  NaN                                     4.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ee6c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USERID', 'FULLNAME', 'EMAIL', 'PHONENUMBER', 'GENDER', 'DOJ',\n",
       "       'SPECIALIZATION', 'DOB', 'CITY', 'STATE', 'EXPERIENCE', 'USERTYPE',\n",
       "       'SUBSCRIBENEWSLETTER', 'TRAININGID', 'TRAINERID', 'TRAINERNAME',\n",
       "       'TRAINERDESIGNATION', 'TRAINERRATING', 'TRAINERSPECIALIZATION',\n",
       "       'TRAININGNAME', 'OPTIMIZEDDURATION', 'DIFFICULTYLEVEL',\n",
       "       'TRAININGSTATUS', 'ASSESSMENT_PERCENTAGE_DONE',\n",
       "       'ASSESSMENT_COMPLETION_TIME_IN_HOURS', 'SCOREACHIEVEDINQUIZ',\n",
       "       'QUIZPASSEDORFAILED', 'RATINGGIVENBYTRAINER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e197747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USERID</th>\n",
       "      <th>FULLNAME</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>PHONENUMBER</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOJ</th>\n",
       "      <th>SPECIALIZATION</th>\n",
       "      <th>DOB</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAINERSPECIALIZATION</th>\n",
       "      <th>TRAININGNAME</th>\n",
       "      <th>OPTIMIZEDDURATION</th>\n",
       "      <th>DIFFICULTYLEVEL</th>\n",
       "      <th>TRAININGSTATUS</th>\n",
       "      <th>ASSESSMENT_PERCENTAGE_DONE</th>\n",
       "      <th>ASSESSMENT_COMPLETION_TIME_IN_HOURS</th>\n",
       "      <th>SCOREACHIEVEDINQUIZ</th>\n",
       "      <th>QUIZPASSEDORFAILED</th>\n",
       "      <th>RATINGGIVENBYTRAINER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>[Continuous Deployment</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>GraphQL</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>PostgreSQL</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emp_181</td>\n",
       "      <td>Andrew Cole</td>\n",
       "      <td>davisgregory@example.org</td>\n",
       "      <td>-9025</td>\n",
       "      <td>Female</td>\n",
       "      <td>23-09-2020</td>\n",
       "      <td>Node.js]</td>\n",
       "      <td>09-09-1996</td>\n",
       "      <td>South Taylorberg</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>...</td>\n",
       "      <td>['Ruby', 'Statistical Analysis', 'Kubernetes',...</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>in_progress</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emp_172</td>\n",
       "      <td>Jonathan Patel</td>\n",
       "      <td>gonzalesbrian@example.org</td>\n",
       "      <td>001-515-605-2768x915</td>\n",
       "      <td>Male</td>\n",
       "      <td>13-01-2021</td>\n",
       "      <td>[MongoDB</td>\n",
       "      <td>14-07-1939</td>\n",
       "      <td>West Paulland</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Data Science Essentials</td>\n",
       "      <td>23.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>pending</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    USERID        FULLNAME                      EMAIL           PHONENUMBER  \\\n",
       "0  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "1  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "2  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "3  Emp_181     Andrew Cole   davisgregory@example.org                 -9025   \n",
       "4  Emp_172  Jonathan Patel  gonzalesbrian@example.org  001-515-605-2768x915   \n",
       "\n",
       "   GENDER         DOJ          SPECIALIZATION         DOB              CITY  \\\n",
       "0  Female  23-09-2020  [Continuous Deployment  09-09-1996  South Taylorberg   \n",
       "1  Female  23-09-2020                 GraphQL  09-09-1996  South Taylorberg   \n",
       "2  Female  23-09-2020              PostgreSQL  09-09-1996  South Taylorberg   \n",
       "3  Female  23-09-2020                Node.js]  09-09-1996  South Taylorberg   \n",
       "4    Male  13-01-2021                [MongoDB  14-07-1939     West Paulland   \n",
       "\n",
       "            STATE  ...                              TRAINERSPECIALIZATION  \\\n",
       "0  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "1  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "2  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "3  North Carolina  ...  ['Ruby', 'Statistical Analysis', 'Kubernetes',...   \n",
       "4         Vermont  ...                                               None   \n",
       "\n",
       "              TRAININGNAME OPTIMIZEDDURATION DIFFICULTYLEVEL TRAININGSTATUS  \\\n",
       "0  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "1  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "2  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "3  Machine Learning Basics              24.0        moderate    in_progress   \n",
       "4  Data Science Essentials              23.0            easy        pending   \n",
       "\n",
       "  ASSESSMENT_PERCENTAGE_DONE ASSESSMENT_COMPLETION_TIME_IN_HOURS  \\\n",
       "0                       87.0                                 NaN   \n",
       "1                       87.0                                 NaN   \n",
       "2                       87.0                                 NaN   \n",
       "3                       87.0                                 NaN   \n",
       "4                        0.0                                 NaN   \n",
       "\n",
       "   SCOREACHIEVEDINQUIZ QUIZPASSEDORFAILED RATINGGIVENBYTRAINER  \n",
       "0                  NaN                                     4.0  \n",
       "1                  NaN                                     4.0  \n",
       "2                  NaN                                     4.0  \n",
       "3                  NaN                                     4.0  \n",
       "4                  NaN                                     4.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64f3ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SCOREACHIEVEDINQUIZ'] = df['SCOREACHIEVEDINQUIZ'].fillna(df['SCOREACHIEVEDINQUIZ'].mean()).astype(int)\n",
    "df['ASSESSMENT_COMPLETION_TIME_IN_HOURS'] = df['ASSESSMENT_COMPLETION_TIME_IN_HOURS'].fillna(df['ASSESSMENT_COMPLETION_TIME_IN_HOURS'].mean()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fff29997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SPECIALIZATION'] = df['SPECIALIZATION'].str.replace(r\"[\\[\\],]\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b0f1d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4131 entries, 0 to 4130\n",
      "Data columns (total 28 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   USERID                               4131 non-null   object \n",
      " 1   FULLNAME                             4131 non-null   object \n",
      " 2   EMAIL                                4131 non-null   object \n",
      " 3   PHONENUMBER                          4131 non-null   object \n",
      " 4   GENDER                               4131 non-null   object \n",
      " 5   DOJ                                  4131 non-null   object \n",
      " 6   SPECIALIZATION                       4131 non-null   object \n",
      " 7   DOB                                  4131 non-null   object \n",
      " 8   CITY                                 4131 non-null   object \n",
      " 9   STATE                                4131 non-null   object \n",
      " 10  EXPERIENCE                           4130 non-null   float64\n",
      " 11  USERTYPE                             4131 non-null   object \n",
      " 12  SUBSCRIBENEWSLETTER                  4131 non-null   object \n",
      " 13  TRAININGID                           4100 non-null   object \n",
      " 14  TRAINERID                            4100 non-null   object \n",
      " 15  TRAINERNAME                          724 non-null    object \n",
      " 16  TRAINERDESIGNATION                   724 non-null    object \n",
      " 17  TRAINERRATING                        724 non-null    float64\n",
      " 18  TRAINERSPECIALIZATION                724 non-null    object \n",
      " 19  TRAININGNAME                         4084 non-null   object \n",
      " 20  OPTIMIZEDDURATION                    4084 non-null   float64\n",
      " 21  DIFFICULTYLEVEL                      4084 non-null   object \n",
      " 22  TRAININGSTATUS                       4100 non-null   object \n",
      " 23  ASSESSMENT_PERCENTAGE_DONE           4100 non-null   float64\n",
      " 24  ASSESSMENT_COMPLETION_TIME_IN_HOURS  4131 non-null   int32  \n",
      " 25  SCOREACHIEVEDINQUIZ                  4131 non-null   int32  \n",
      " 26  QUIZPASSEDORFAILED                   4100 non-null   object \n",
      " 27  RATINGGIVENBYTRAINER                 4100 non-null   float64\n",
      "dtypes: float64(5), int32(2), object(21)\n",
      "memory usage: 871.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e158be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>SPECIALIZATION</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "      <th>DIFFICULTYLEVEL</th>\n",
       "      <th>TRAININGNAME</th>\n",
       "      <th>OPTIMIZEDDURATION</th>\n",
       "      <th>SCOREACHIEVEDINQUIZ</th>\n",
       "      <th>ASSESSMENT_COMPLETION_TIME_IN_HOURS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Continuous Deployment</td>\n",
       "      <td>17.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>GraphQL</td>\n",
       "      <td>17.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>PostgreSQL</td>\n",
       "      <td>17.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Node.js</td>\n",
       "      <td>17.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>MongoDB</td>\n",
       "      <td>17.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>Data Science Essentials</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>Female</td>\n",
       "      <td>Docker</td>\n",
       "      <td>20.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>Male</td>\n",
       "      <td>Behavior-Driven Development</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>Male</td>\n",
       "      <td>Angular</td>\n",
       "      <td>9.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>Male</td>\n",
       "      <td>Continuous Integration</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>Male</td>\n",
       "      <td>Docker</td>\n",
       "      <td>11.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4131 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GENDER                SPECIALIZATION  EXPERIENCE DIFFICULTYLEVEL  \\\n",
       "0     Female         Continuous Deployment        17.0        moderate   \n",
       "1     Female                       GraphQL        17.0        moderate   \n",
       "2     Female                    PostgreSQL        17.0        moderate   \n",
       "3     Female                       Node.js        17.0        moderate   \n",
       "4       Male                       MongoDB        17.0            easy   \n",
       "...      ...                           ...         ...             ...   \n",
       "4126  Female                        Docker        20.0            None   \n",
       "4127    Male   Behavior-Driven Development        11.0            None   \n",
       "4128    Male                       Angular         9.0            None   \n",
       "4129    Male        Continuous Integration        11.0            None   \n",
       "4130    Male                        Docker        11.0            None   \n",
       "\n",
       "                 TRAININGNAME  OPTIMIZEDDURATION  SCOREACHIEVEDINQUIZ  \\\n",
       "0     Machine Learning Basics               24.0                   48   \n",
       "1     Machine Learning Basics               24.0                   48   \n",
       "2     Machine Learning Basics               24.0                   48   \n",
       "3     Machine Learning Basics               24.0                   48   \n",
       "4     Data Science Essentials               23.0                   48   \n",
       "...                       ...                ...                  ...   \n",
       "4126                     None                NaN                   48   \n",
       "4127                     None                NaN                   48   \n",
       "4128                     None                NaN                   48   \n",
       "4129                     None                NaN                   48   \n",
       "4130                     None                NaN                   48   \n",
       "\n",
       "      ASSESSMENT_COMPLETION_TIME_IN_HOURS  \n",
       "0                                      29  \n",
       "1                                      29  \n",
       "2                                      29  \n",
       "3                                      29  \n",
       "4                                      29  \n",
       "...                                   ...  \n",
       "4126                                   29  \n",
       "4127                                   29  \n",
       "4128                                   29  \n",
       "4129                                   29  \n",
       "4130                                   29  \n",
       "\n",
       "[4131 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['GENDER', 'SPECIALIZATION', 'EXPERIENCE', 'DIFFICULTYLEVEL', 'TRAININGNAME', 'OPTIMIZEDDURATION', 'SCOREACHIEVEDINQUIZ', 'ASSESSMENT_COMPLETION_TIME_IN_HOURS']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79362f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score , classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume df1 is your preprocessed DataFrame with features and target column 'trainingName'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df1[['GENDER', 'SPECIALIZATION', 'EXPERIENCE', 'DIFFICULTYLEVEL', 'TRAININGNAME', 'OPTIMIZEDDURATION']]\n",
    "y = df1['SCOREACHIEVEDINQUIZ']\n",
    "\n",
    "# Encode categorical variables if needed (e.g., one-hot encoding)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "298fe1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.27085852478838\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78d44ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\706354182.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for the new data\n",
    "new_data = {\n",
    "    'GENDER': ['male'],\n",
    "    'SPECIALIZATION': ['Azure'],\n",
    "    'EXPERIENCE': [10],\n",
    "    'DIFFICULTYLEVEL': ['moderate'],\n",
    "    'TRAININGNAME': ['Machine Learning Basics'],\n",
    "    'OPTIMIZEDDURATION': [24]\n",
    "}\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "df_new_encoded = pd.get_dummies(df_new)\n",
    "\n",
    "missing_cols = set(X_encoded.columns) - set(df_new_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    df_new_encoded[col] = 0 \n",
    "\n",
    "df_new_encoded = df_new_encoded[X_encoded.columns]\n",
    "\n",
    "y_pred_new = xgb_classifier.predict(df_new_encoded)\n",
    "\n",
    "predicted_scores = label_encoder .inverse_transform(y_pred_new)\n",
    "\n",
    "print(predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea68c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37e0c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[['GENDER', 'SPECIALIZATION', 'EXPERIENCE', 'DIFFICULTYLEVEL', 'TRAININGNAME', 'OPTIMIZEDDURATION']]\n",
    "y = df1['ASSESSMENT_COMPLETION_TIME_IN_HOURS']\n",
    "\n",
    "# Encode categorical variables if needed (e.g., one-hot encoding)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cb966b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.02902055622734\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52a94b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\KaustubhGupta\\AppData\\Local\\Temp\\ipykernel_2004\\1061772407.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for the new data\n",
    "new_data = {\n",
    "    'GENDER': ['male'],\n",
    "    'SPECIALIZATION': ['Azure'],\n",
    "    'EXPERIENCE': [10],\n",
    "    'DIFFICULTYLEVEL': ['moderate'],\n",
    "    'TRAININGNAME': ['Machine Learning Basics'],\n",
    "    'OPTIMIZEDDURATION': [20]\n",
    "}\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "df_new_encoded = pd.get_dummies(df_new)\n",
    "\n",
    "missing_cols = set(X_encoded.columns) - set(df_new_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    df_new_encoded[col] = 0 \n",
    "\n",
    "df_new_encoded = df_new_encoded[X_encoded.columns]\n",
    "\n",
    "y_pred_new = xgb_classifier.predict(df_new_encoded)\n",
    "\n",
    "predicted_time = label_encoder .inverse_transform(y_pred_new)\n",
    "\n",
    "print(predicted_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77598a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
