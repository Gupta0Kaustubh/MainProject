{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ddaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa8851a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../ConversionAndRetrieval/TotalInfo.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ee6c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'fullName', 'gender', 'dob', 'doj', 'specialization', 'city',\n",
       "       'state', 'experience', 'userType', 'trainingId', 'trainingName',\n",
       "       'trainingStatus', 'optimizedDuration', 'startDate', 'endDate',\n",
       "       'TrainerId', 'trainerName', 'trainerDesignation', 'difficultyLevel',\n",
       "       'assessment_completion_time_in_hours', 'assessment_percentage_done',\n",
       "       'quizPassedOrFailed', 'ratingGivenByTrainer', 'scoreAchievedInQuiz'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e197747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>fullName</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>doj</th>\n",
       "      <th>specialization</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>experience</th>\n",
       "      <th>userType</th>\n",
       "      <th>...</th>\n",
       "      <th>endDate</th>\n",
       "      <th>TrainerId</th>\n",
       "      <th>trainerName</th>\n",
       "      <th>trainerDesignation</th>\n",
       "      <th>difficultyLevel</th>\n",
       "      <th>assessment_completion_time_in_hours</th>\n",
       "      <th>assessment_percentage_done</th>\n",
       "      <th>quizPassedOrFailed</th>\n",
       "      <th>ratingGivenByTrainer</th>\n",
       "      <th>scoreAchievedInQuiz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Emp_44</td>\n",
       "      <td>Nicole Parker</td>\n",
       "      <td>Female</td>\n",
       "      <td>16-06-2022</td>\n",
       "      <td>24-09-2023</td>\n",
       "      <td>'Docker'</td>\n",
       "      <td>Johnchester</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>Emp_195</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Technical Architect</td>\n",
       "      <td>easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emp_44</td>\n",
       "      <td>Nicole Parker</td>\n",
       "      <td>Female</td>\n",
       "      <td>16-06-2022</td>\n",
       "      <td>24-09-2023</td>\n",
       "      <td>'Penetration Testing'</td>\n",
       "      <td>Johnchester</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>Emp_195</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Technical Architect</td>\n",
       "      <td>easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emp_44</td>\n",
       "      <td>Nicole Parker</td>\n",
       "      <td>Female</td>\n",
       "      <td>16-06-2022</td>\n",
       "      <td>24-09-2023</td>\n",
       "      <td>'Artificial Intelligence'</td>\n",
       "      <td>Johnchester</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>Emp_195</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Technical Architect</td>\n",
       "      <td>easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emp_44</td>\n",
       "      <td>Nicole Parker</td>\n",
       "      <td>Female</td>\n",
       "      <td>16-06-2022</td>\n",
       "      <td>24-09-2023</td>\n",
       "      <td>'Azure'</td>\n",
       "      <td>Johnchester</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>User</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>Emp_195</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Technical Architect</td>\n",
       "      <td>easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emp_51</td>\n",
       "      <td>Richard Jenkins</td>\n",
       "      <td>Female</td>\n",
       "      <td>27-04-1931</td>\n",
       "      <td>10-10-2022</td>\n",
       "      <td>'CI/CD'</td>\n",
       "      <td>Carterton</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>17</td>\n",
       "      <td>User</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>Emp_195</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Technical Architect</td>\n",
       "      <td>easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId         fullName  gender         dob         doj  \\\n",
       "0  Emp_44    Nicole Parker  Female  16-06-2022  24-09-2023   \n",
       "1  Emp_44    Nicole Parker  Female  16-06-2022  24-09-2023   \n",
       "2  Emp_44    Nicole Parker  Female  16-06-2022  24-09-2023   \n",
       "3  Emp_44    Nicole Parker  Female  16-06-2022  24-09-2023   \n",
       "4  Emp_51  Richard Jenkins  Female  27-04-1931  10-10-2022   \n",
       "\n",
       "               specialization         city         state  experience userType  \\\n",
       "0                    'Docker'  Johnchester    New Jersey           1     User   \n",
       "1       'Penetration Testing'  Johnchester    New Jersey           1     User   \n",
       "2   'Artificial Intelligence'  Johnchester    New Jersey           1     User   \n",
       "3                     'Azure'  Johnchester    New Jersey           1     User   \n",
       "4                     'CI/CD'    Carterton  Pennsylvania          17     User   \n",
       "\n",
       "   ...     endDate TrainerId trainerName   trainerDesignation difficultyLevel  \\\n",
       "0  ...  2024-02-10   Emp_195     Michael  Technical Architect            easy   \n",
       "1  ...  2024-02-10   Emp_195     Michael  Technical Architect            easy   \n",
       "2  ...  2024-02-10   Emp_195     Michael  Technical Architect            easy   \n",
       "3  ...  2024-02-10   Emp_195     Michael  Technical Architect            easy   \n",
       "4  ...  2024-02-10   Emp_195     Michael  Technical Architect            easy   \n",
       "\n",
       "  assessment_completion_time_in_hours assessment_percentage_done  \\\n",
       "0                                 NaN                          0   \n",
       "1                                 NaN                          0   \n",
       "2                                 NaN                          0   \n",
       "3                                 NaN                          0   \n",
       "4                                 NaN                          0   \n",
       "\n",
       "  quizPassedOrFailed ratingGivenByTrainer scoreAchievedInQuiz  \n",
       "0                NaN                    4                 NaN  \n",
       "1                NaN                    4                 NaN  \n",
       "2                NaN                    4                 NaN  \n",
       "3                NaN                    4                 NaN  \n",
       "4                NaN                    1                 NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "64f3ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['scoreAchievedInQuiz'] = data['scoreAchievedInQuiz'].fillna(data['scoreAchievedInQuiz'].mean())\n",
    "data['assessment_completion_time_in_hours'] = data['assessment_completion_time_in_hours'].fillna(data['assessment_completion_time_in_hours'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fff29997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['specialization'] = data['specialization'].replace(to_replace=r'[\\'\\\"]', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b0f1d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 964 entries, 0 to 963\n",
      "Data columns (total 25 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   userId                               964 non-null    object \n",
      " 1   fullName                             964 non-null    object \n",
      " 2   gender                               964 non-null    object \n",
      " 3   dob                                  964 non-null    object \n",
      " 4   doj                                  964 non-null    object \n",
      " 5   specialization                       964 non-null    object \n",
      " 6   city                                 964 non-null    object \n",
      " 7   state                                964 non-null    object \n",
      " 8   experience                           964 non-null    int64  \n",
      " 9   userType                             964 non-null    object \n",
      " 10  trainingId                           964 non-null    object \n",
      " 11  trainingName                         964 non-null    object \n",
      " 12  trainingStatus                       964 non-null    object \n",
      " 13  optimizedDuration                    964 non-null    int64  \n",
      " 14  startDate                            964 non-null    object \n",
      " 15  endDate                              964 non-null    object \n",
      " 16  TrainerId                            964 non-null    object \n",
      " 17  trainerName                          964 non-null    object \n",
      " 18  trainerDesignation                   964 non-null    object \n",
      " 19  difficultyLevel                      964 non-null    object \n",
      " 20  assessment_completion_time_in_hours  964 non-null    float64\n",
      " 21  assessment_percentage_done           964 non-null    int64  \n",
      " 22  quizPassedOrFailed                   380 non-null    object \n",
      " 23  ratingGivenByTrainer                 964 non-null    int64  \n",
      " 24  scoreAchievedInQuiz                  964 non-null    float64\n",
      "dtypes: float64(2), int64(4), object(19)\n",
      "memory usage: 188.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e158be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>specialization</th>\n",
       "      <th>experience</th>\n",
       "      <th>difficultyLevel</th>\n",
       "      <th>trainingName</th>\n",
       "      <th>optimizedDuration</th>\n",
       "      <th>scoreAchievedInQuiz</th>\n",
       "      <th>assessment_completion_time_in_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Docker</td>\n",
       "      <td>1</td>\n",
       "      <td>easy</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>6</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>Penetration Testing</td>\n",
       "      <td>1</td>\n",
       "      <td>easy</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>6</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>1</td>\n",
       "      <td>easy</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>6</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Azure</td>\n",
       "      <td>1</td>\n",
       "      <td>easy</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>6</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>CI/CD</td>\n",
       "      <td>17</td>\n",
       "      <td>easy</td>\n",
       "      <td>Machine Learning Basics</td>\n",
       "      <td>6</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Male</td>\n",
       "      <td>Angular</td>\n",
       "      <td>19</td>\n",
       "      <td>hard</td>\n",
       "      <td>Introduction to JavaScript</td>\n",
       "      <td>11</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Male</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>19</td>\n",
       "      <td>hard</td>\n",
       "      <td>Introduction to JavaScript</td>\n",
       "      <td>11</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Male</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>19</td>\n",
       "      <td>hard</td>\n",
       "      <td>Introduction to JavaScript</td>\n",
       "      <td>11</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>Male</td>\n",
       "      <td>Git</td>\n",
       "      <td>19</td>\n",
       "      <td>hard</td>\n",
       "      <td>Introduction to JavaScript</td>\n",
       "      <td>11</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>Male</td>\n",
       "      <td>Angular</td>\n",
       "      <td>19</td>\n",
       "      <td>hard</td>\n",
       "      <td>Introduction to JavaScript</td>\n",
       "      <td>11</td>\n",
       "      <td>47.347368</td>\n",
       "      <td>27.957895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender            specialization  experience difficultyLevel  \\\n",
       "0    Female                    Docker           1            easy   \n",
       "1    Female       Penetration Testing           1            easy   \n",
       "2    Female   Artificial Intelligence           1            easy   \n",
       "3    Female                     Azure           1            easy   \n",
       "4    Female                     CI/CD          17            easy   \n",
       "..      ...                       ...         ...             ...   \n",
       "959    Male                   Angular          19            hard   \n",
       "960    Male          Machine Learning          19            hard   \n",
       "961    Male                      Ruby          19            hard   \n",
       "962    Male                       Git          19            hard   \n",
       "963    Male                   Angular          19            hard   \n",
       "\n",
       "                   trainingName  optimizedDuration  scoreAchievedInQuiz  \\\n",
       "0       Machine Learning Basics                  6            47.347368   \n",
       "1       Machine Learning Basics                  6            47.347368   \n",
       "2       Machine Learning Basics                  6            47.347368   \n",
       "3       Machine Learning Basics                  6            47.347368   \n",
       "4       Machine Learning Basics                  6            47.347368   \n",
       "..                          ...                ...                  ...   \n",
       "959  Introduction to JavaScript                 11            47.347368   \n",
       "960  Introduction to JavaScript                 11            47.347368   \n",
       "961  Introduction to JavaScript                 11            47.347368   \n",
       "962  Introduction to JavaScript                 11            47.347368   \n",
       "963  Introduction to JavaScript                 11            47.347368   \n",
       "\n",
       "     assessment_completion_time_in_hours  \n",
       "0                              27.957895  \n",
       "1                              27.957895  \n",
       "2                              27.957895  \n",
       "3                              27.957895  \n",
       "4                              27.957895  \n",
       "..                                   ...  \n",
       "959                            27.957895  \n",
       "960                            27.957895  \n",
       "961                            27.957895  \n",
       "962                            27.957895  \n",
       "963                            27.957895  \n",
       "\n",
       "[964 rows x 8 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data[['gender', 'specialization', 'experience', 'difficultyLevel', 'trainingName', 'optimizedDuration', 'scoreAchievedInQuiz', 'assessment_completion_time_in_hours']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "79362f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score , classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume df1 is your preprocessed DataFrame with features and target column 'trainingName'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df1[['gender', 'specialization', 'experience', 'difficultyLevel', 'trainingName', 'optimizedDuration', 'assessment_completion_time_in_hours']]\n",
    "y = df1['scoreAchievedInQuiz']\n",
    "\n",
    "# Encode categorical variables if needed (e.g., one-hot encoding)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "298fe1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.62068965517241\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78d44ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\1833043220.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for the new data\n",
    "new_data = {\n",
    "    'gender': ['male'],\n",
    "    'specialization': ['Azure'],\n",
    "    'experience': [10],\n",
    "    'difficultyLevel': ['moderate'],\n",
    "    'trainingName': ['Machine Learning Basics'],\n",
    "    'optimizedDuration': [12],\n",
    "    'assessment_completion_time_in_hours': [16]\n",
    "}\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "df_new_encoded = pd.get_dummies(df_new)\n",
    "\n",
    "missing_cols = set(X_encoded.columns) - set(df_new_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    df_new_encoded[col] = 0 \n",
    "\n",
    "df_new_encoded = df_new_encoded[X_encoded.columns]\n",
    "\n",
    "y_pred_new = xgb_classifier.predict(df_new_encoded)\n",
    "\n",
    "predicted_scores = label_encoder .inverse_transform(y_pred_new)\n",
    "\n",
    "print(predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea68c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37e0c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1[['gender', 'specialization', 'experience', 'difficultyLevel', 'trainingName', 'scoreAchievedInQuiz', 'optimizedDuration']]\n",
    "y = df1['assessment_completion_time_in_hours']\n",
    "\n",
    "# Encode categorical variables if needed (e.g., one-hot encoding)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2cb966b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.62068965517241\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52a94b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n",
      "C:\\Users\\kaust\\AppData\\Local\\Temp\\ipykernel_18740\\2903486979.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_new_encoded[col] = 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for the new data\n",
    "new_data = {\n",
    "    'gender': ['male'],\n",
    "    'specialization': ['Azure'],\n",
    "    'experience': [10],\n",
    "    'difficultyLevel': ['moderate'],\n",
    "    'trainingName': ['Machine Learning Basics'],\n",
    "    'scoreAchievedInQuiz': [80],\n",
    "    'assessment_completion_time_in_hours': [16]\n",
    "}\n",
    "df_new = pd.DataFrame(new_data)\n",
    "\n",
    "df_new_encoded = pd.get_dummies(df_new)\n",
    "\n",
    "missing_cols = set(X_encoded.columns) - set(df_new_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    df_new_encoded[col] = 0 \n",
    "\n",
    "df_new_encoded = df_new_encoded[X_encoded.columns]\n",
    "\n",
    "y_pred_new = xgb_classifier.predict(df_new_encoded)\n",
    "\n",
    "predicted_scores = label_encoder.inverse_transform(y_pred_new)\n",
    "\n",
    "print(predicted_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2b7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
